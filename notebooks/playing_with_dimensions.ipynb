{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T19:04:20.726080Z",
     "start_time": "2019-07-19T19:04:20.156913Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T19:46:18.535321Z",
     "start_time": "2019-07-19T19:46:18.527183Z"
    }
   },
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(\n",
    "in_channels=1,\n",
    "out_channels=8,\n",
    "kernel_size=3,\n",
    "stride=1,\n",
    "padding=0)\n",
    "pool = nn.MaxPool2d(\n",
    "        kernel_size=3\n",
    "        )\n",
    "# convlstm1 = ConvLSTMCell(\n",
    "#            shape=[self.size1,self.size1], \n",
    "#            input_channel=8, \n",
    "#            filter_size=3,\n",
    "#            hidden_size=self.hidden_size)\n",
    "# convlstm2 = ConvLSTMCell(\n",
    "#            shape=[self.size1,self.size1], \n",
    "#            input_channel=self.hidden_size,\n",
    "#            filter_size=3,\n",
    "#            hidden_size=self.hidden_size)\n",
    "deconv = nn.ConvTranspose2d(\n",
    "           in_channels=64 , \n",
    "           out_channels=1, \n",
    "           kernel_size=6,\n",
    "           stride=3,\n",
    "           padding=0, \n",
    "           output_padding=1, \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T19:45:40.814074Z",
     "start_time": "2019-07-19T19:45:40.706636Z"
    },
    "code_folding": [
     10,
     66
    ]
   },
   "outputs": [],
   "source": [
    "# Based on the tensorflow implementation by yunbo:\n",
    "# https://github.com/Yunbo426/predrnn-pp/blob/master/layers/CausalLSTMCell.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CausalLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels, layer_name, filter_size, num_hidden_in, num_hidden_out,\n",
    "                 seq_shape, forget_bias=1.0, initializer=0.001):\n",
    "        super(CausalLSTMCell,self).__init__()\n",
    "        \n",
    "        self.layer_name = layer_name\n",
    "        self.filter_size = filter_size\n",
    "        self.input_channels = input_channels\n",
    "        self.num_hidden_in = num_hidden_in\n",
    "        self.num_hidden = num_hidden_out\n",
    "        self.batch = seq_shape[0]\n",
    "        self.x_channels = 1\n",
    "        self.height = seq_shape[2]\n",
    "        self.width = seq_shape[3]\n",
    "        # self.layer_norm = tln\n",
    "        self._forget_bias = forget_bias\n",
    "\n",
    "        #########\n",
    "        #NOT SURE ABOUT INPUT CHANNELS\n",
    "        #########\n",
    "        self.conv_h = nn.Conv2d(in_channels=self.num_hidden, ###hidden state has similar spatial struture as inputs, we simply concatenate them on the feature dimension\n",
    "                           out_channels=self.num_hidden*4, ##lstm has four gates\n",
    "                           kernel_size=self.filter_size,\n",
    "                           stride=1,\n",
    "                           padding=1\n",
    "        )\n",
    "\n",
    "        self.conv_c = nn.Conv2d(in_channels=self.num_hidden, ###hidden state has similar spatial struture as inputs, we simply concatenate them on the feature dimension\n",
    "                           out_channels=self.num_hidden*3, \n",
    "                           kernel_size=self.filter_size,\n",
    "                           stride=1,\n",
    "                           padding=1\n",
    "        )\n",
    "\n",
    "        self.conv_m = nn.Conv2d(in_channels=self.num_hidden_in, ###hidden state has similar spatial struture as inputs, we simply concatenate them on the feature dimension\n",
    "                           out_channels=self.num_hidden*3, \n",
    "                           kernel_size=self.filter_size,\n",
    "                           stride=1,\n",
    "                           padding=1\n",
    "        )\n",
    "\n",
    "        self.conv_x = nn.Conv2d(in_channels=self.input_channels, ###hidden state has similar spatial struture as inputs, we simply concatenate them on the feature dimension\n",
    "                           out_channels=self.num_hidden*7, \n",
    "                           kernel_size=self.filter_size,\n",
    "                           stride=1,\n",
    "                           padding=1)\n",
    "\n",
    "        self.conv_o = nn.Conv2d(in_channels=self.num_hidden,out_channels=self.num_hidden, \n",
    "                           kernel_size=self.filter_size,\n",
    "                           stride=1,\n",
    "                           padding=1)\n",
    "        \n",
    "        self.conv_1_1 =  nn.Conv2d(in_channels=self.num_hidden*2,out_channels=self.num_hidden, \n",
    "                           kernel_size=1,\n",
    "                           stride=1,\n",
    "                           padding=0)\n",
    "\n",
    "    def forward(self,x,h,c,m):\n",
    "        if h is None:\n",
    "            h = torch.zeros([self.batch,self.num_hidden,self.height,self.width])\n",
    "        if c is None:\n",
    "            c = torch.zeros([self.batch,self.num_hidden,self.height,self.width])\n",
    "        if m is None:\n",
    "            m = torch.zeros([self.batch,self.num_hidden_in,self.height,self.width])\n",
    "\n",
    "        h_cc = self.conv_h(h)\n",
    "        c_cc = self.conv_c(c)\n",
    "        m_cc = self.conv_m(m)\n",
    "\n",
    "        i_h, g_h, f_h, o_h = torch.chunk(h_cc, 4, dim=1)\n",
    "        i_c, g_c, f_c = torch.chunk(c_cc, 3, dim=1)\n",
    "        i_m, f_m, m_m = torch.chunk(m_cc, 3, dim=1)\n",
    "\n",
    "        if x is None:\n",
    "            i = torch.sigmoid(i_h + i_c)\n",
    "            f = torch.sigmoid(f_h + f_c + self._forget_bias)\n",
    "            g = torch.tanh(g_h + g_c)\n",
    "\n",
    "        else:\n",
    "            x_cc = self.conv_x(x)\n",
    "            \n",
    "            i_x, g_x, f_x, o_x, i_x_, g_x_, f_x_ = torch.chunk(x_cc, 7, dim = 1)\n",
    "            print(i_x.shape,i_h.shape,i_c.shape)\n",
    "            i = torch.sigmoid(i_x + i_h + i_c)\n",
    "            f = torch.sigmoid(f_x + f_h + f_c + self._forget_bias)\n",
    "            g = torch.tanh(g_x + g_h + g_c)\n",
    "        \n",
    "        c_new = f * c + i * g\n",
    "        \n",
    "        c2m = self.conv_h(c_new)\n",
    "\n",
    "        i_c, g_c, f_c, o_c = torch.chunk(c2m, 4, dim=1)\n",
    "\n",
    "        if x is None:\n",
    "            ii = torch.sigmoid(i_c + i_m)\n",
    "            ff = torch.sigmoid(f_c + f_m + self._forget_bias)\n",
    "            gg = torch.tanh(g_c)\n",
    "        else:\n",
    "            ii = torch.sigmoid(i_c + i_x_ + i_m)\n",
    "            ff = torch.sigmoid(f_c + f_x_ + f_m + self._forget_bias)\n",
    "            gg = torch.tanh(g_c + g_x_)\n",
    "\n",
    "        m_new = ff * torch.tanh(m_m) + ii * gg\n",
    "        o_m = self.conv_o(m_new)        \n",
    "\n",
    "        if x is None:\n",
    "            o = torch.tanh(o_h + o_c + o_m)\n",
    "        else:\n",
    "            o = torch.tanh(o_x + o_h + o_c + o_m)\n",
    "        \n",
    "        cell = torch.cat((c_new, m_new),1)\n",
    "        print(cell.shape)\n",
    "        cell = self.conv_1_1(cell)\n",
    "        print(cell.shape)\n",
    "        h_new = o * torch.tanh(cell)\n",
    "\n",
    "        return h_new, c_new, m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T19:45:42.680569Z",
     "start_time": "2019-07-19T19:45:42.667359Z"
    }
   },
   "outputs": [],
   "source": [
    "clstm = CausalLSTMCell(8,'karas',3,64,64,[5,1,32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T19:46:20.268602Z",
     "start_time": "2019-07-19T19:46:20.108821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64, 32, 32]) torch.Size([5, 64, 32, 32]) torch.Size([5, 64, 32, 32])\n",
      "torch.Size([5, 128, 32, 32])\n",
      "torch.Size([5, 64, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 100, 100])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([5,1,100,100])\n",
    "out = conv(x)\n",
    "out = pool(out)\n",
    "out,_,_  = clstm(out,None,None,None) \n",
    "out= deconv(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:06:41.546113Z",
     "start_time": "2019-07-13T16:06:41.536060Z"
    }
   },
   "outputs": [],
   "source": [
    "shape = [5,1,100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:06:41.594621Z",
     "start_time": "2019-07-13T16:06:41.549262Z"
    }
   },
   "outputs": [],
   "source": [
    "cell = CausalLSTMCell(1,'axristo',3,64,192,shape,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:06:41.604314Z",
     "start_time": "2019-07-13T16:06:41.601470Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:06:45.402295Z",
     "start_time": "2019-07-13T16:06:41.608155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 384, 100, 100])\n",
      "torch.Size([5, 192, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "a = cell.forward(x,None,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:06:45.428698Z",
     "start_time": "2019-07-13T16:06:45.404468Z"
    }
   },
   "outputs": [],
   "source": [
    "c = torch.zeros([5,192,100,100])\n",
    "m = torch.zeros([5,192,100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:06:45.547921Z",
     "start_time": "2019-07-13T16:06:45.430924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 384, 100, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((c,m),1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T16:07:37.137767Z",
     "start_time": "2019-07-13T16:07:37.112102Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d74f1bcdd37c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:30:19.395605Z",
     "start_time": "2019-07-13T22:30:19.151476Z"
    }
   },
   "outputs": [],
   "source": [
    "# based on the tensorflow implementation by 'yunbo':\n",
    "# https://github.com/Yunbo426/predrnn-pp/blob/master/nets/predrnn_pp.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from model_architectures.pred_rnn_pp.CausalLSTMCell import CausalLSTMCell as clstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:39:23.021700Z",
     "start_time": "2019-07-13T22:39:22.766992Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# based on the tensorflow implementation by 'yunbo':\n",
    "# https://github.com/Yunbo426/predrnn-pp/blob/master/nets/predrnn_pp.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model_architectures.pred_rnn_pp.CausalLSTMCell import CausalLSTMCell as clstm\n",
    "\n",
    "class PredRNNPP(nn.Module):\n",
    "\n",
    "    def __init__(self,input_shape,seq_input,seq_output,batch_size,num_hidden,device):\n",
    "        super(PredRNNPP,self).__init__()\n",
    "\n",
    "        self.seq_input = seq_input\n",
    "        self.seq_output = seq_output\n",
    "        self.seq_length = seq_input + seq_output\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape #this is the dimensionality of the frame\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_layers = len(num_hidden)\n",
    "\n",
    "        self.lstm = []\n",
    "        self.output_channels = 1\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.num_hidden[self.num_layers-1], ###hidden state has similar spatial struture as inputs, we simply concatenate them on the feature dimension\n",
    "                           out_channels=self.output_channels, \n",
    "                           kernel_size=1,\n",
    "                           stride=1,\n",
    "                           padding=0)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            if i == 0:\n",
    "                num_hidden_in = self.num_hidden[self.num_layers-1]\n",
    "                input_channels = 1\n",
    "            else:\n",
    "                num_hidden_in = self.num_hidden[i-1]\n",
    "                input_channels = self.num_hidden[i-1]\n",
    "\n",
    "            new_cell = clstm(input_channels,'lstm_'+str(i+1),3,num_hidden_in,self.num_hidden[i],self.input_shape)\n",
    "            self.lstm.append(new_cell)\n",
    "\n",
    "        self.ghu = None\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        cell = []\n",
    "        hidden = []\n",
    "        mem = None\n",
    "        for i in range(self.num_layers):\n",
    "            cell.append(None)\n",
    "            hidden.append(None)\n",
    "        output = []\n",
    "        x_gen = None\n",
    "        # x has shape B S H W\n",
    "        for t in range(self.seq_length-1):\n",
    "            if t < self.seq_input:\n",
    "                inputs = x[:,t,:,:].unsqueeze(1)\n",
    "            else:\n",
    "                inputs = x_gen\n",
    "            \n",
    "            hidden[0], cell[0], mem = self.lstm[0].forward(inputs, hidden[0],cell[0], mem)\n",
    "            #z_t = self.ghu(self.hidden[0], z_t)\n",
    "            z_t = hidden[0]\n",
    "            hidden[1],cell[1],mem = self.lstm[1](z_t, hidden[1], cell[1], mem)\n",
    "            for i in range(2, self.num_layers):\n",
    "                hidden[i], cell[i], mem = self.lstm[i](hidden[i-1], hidden[i], cell[i], mem)\n",
    "                x_gen = self.conv(hidden[num_layers-1])\n",
    "                output.append(x_gen)\n",
    "\n",
    "        output = torch.stack(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:39:24.985187Z",
     "start_time": "2019-07-13T22:39:24.982389Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.zeros([5,12,100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:39:27.189692Z",
     "start_time": "2019-07-13T22:39:27.180237Z"
    }
   },
   "outputs": [],
   "source": [
    "num_hidden = [4,8,8,8]\n",
    "predrnn = PredRNNPP(X.shape,12,10,5,num_hidden,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:39:29.588061Z",
     "start_time": "2019-07-13T22:39:29.516714Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 56 1 3 3, expected input[5, 4, 100, 100] to have 1 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-591a213002eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-7e43b6763ba2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m#z_t = self.ghu(self.hidden[0], z_t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dissertation/Mobile-Data-Forecasting-With-Spatio-Temporal-Networks/model_architectures/pred_rnn_pp/CausalLSTMCell.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h, c, m)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mx_cc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mi_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_x_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_x_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_x_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 56 1 3 3, expected input[5, 4, 100, 100] to have 1 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "predrnn.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlp)",
   "language": "python",
   "name": "mlp"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
